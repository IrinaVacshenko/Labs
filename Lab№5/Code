import random
import sklearn.linear_model as lm
from scipy.stats import f, t
from functools import partial
from pyDOE2 import *
import time

x_range = ((-5, 8), (-1, 4), (-4, 2))
x_maxavr = (8 + 4 - 2)/3
x_minavr = (-5 - 1 - 4)/3

y_max = 200 + int(x_maxavr)
y_min = 200 + int(x_minavr)
y_min_max = [y_min, y_max]

def suma(x, b):
    y = sum([x[i] * b[i] for i in range(len(x))])
    return y



def matrixs(n, m):
    y = np.random.randint(*y_min_max, size=(n, m))
    norm_matrix = ccdesign(3, center=(0, 1))
    norm_matrix = np.insert(norm_matrix, 0, 1, axis=1)

    for i in range(4, 11):
        norm_matrix = np.insert(norm_matrix, i, 0, axis=1)

    l = 1.215

    for i in range(len(norm_matrix)):
        for j in range(len(norm_matrix[i])):
            if norm_matrix[i][j] < -1 or norm_matrix[i][j] > 1:
                if norm_matrix[i][j] < 0:
                    norm_matrix[i][j] = -l
                else:
                    norm_matrix[i][j] = l

    def addnums(x):
        for i in range(len(x)):
            x[i][4] = x[i][1] * x[i][2]
            x[i][5] = x[i][1] * x[i][3]
            x[i][6] = x[i][2] * x[i][3]
            x[i][7] = x[i][1] * x[i][3] * x[i][2]
            x[i][8] = x[i][1] ** 2
            x[i][9] = x[i][2] ** 2
            x[i][10] = x[i][3] ** 2
        return x


    x = np.ones((15, 11,), dtype=np.int64)
    for i in range(8):
        for j in range(1, 4):
            if norm_matrix[i][j] == -1:
                x[i][j] = x_range[j - 1][0]
            else:
                x[i][j] = x_range[j - 1][1]

    for i in range(8, len(x)):
        for j in range(1, 3):
            x[i][j] = (x_range[j - 1][0] + x_range[j - 1][1]) / 2

    dx = [x_range[i][1] - (x_range[i][0] + x_range[i][1]) / 2 for i in range(3)]

    x[8][1] = l * dx[0] + x[9][1]
    x[9][1] = -l * dx[0] + x[9][1]
    x[10][2] = l * dx[1] + x[9][2]
    x[11][2] = -l * dx[1] + x[9][2]
    x[12][3] = l * dx[2] + x[9][3]
    x[13][3] = -l * dx[2] + x[9][3]

    x = addnums(x)
    print("Нормована матриця:")
    for i in norm_matrix:
        print([round(x, 2) for x in i])
    return x, y, norm_matrix


def find_coef(X, Y, norm=False):
    skm = lm.LinearRegression(fit_intercept=False)
    skm.fit(X, Y)
    B = skm.coef_

    if norm == 1:
        print('\nКоефіцієнти з нормованими X:')
    else:
        print('\nКоефіцієнти рівняння регресії:')
    B = [round(i, 3) for i in B]
    print('\nРезультат рівняння зі знайденими коефіцієнтами:\n', np.dot(X, B))
    return B

def count_dispersion(y, y_avarg, n, m):
    y_var = np.var(y, axis=1)
    return y_var
    
#------------
def check_criter_Cochran(y, y_avarg, n, m):
    start_time = time.monotonic()
    S_kv = count_dispersion(y, y_avarg, n, m)
    Gp = max(S_kv) / sum(S_kv)
    print('\nПеревірка за критерієм Кохрена')
    end_time = time.monotonic()
    time_C = (end_time - start_time) * 1000
    print(f"Час виконання Кохрена: {time_C:.3f} ms")
    return Gp
#------------

def cohren(f1, f2, q=0.05):
    q1 = q / f1
    fisher_value = f.ppf(q=1 - q1, dfn=f2, dfd=(f1 - 1) * f2)
    return fisher_value / (fisher_value + f1 - 1)


def bs(x, y_avarg, n):
    res = [sum(1 * y for y in y_avarg) / n]
    for i in range(3):
        b = sum(j[0] * j[1] for j in zip(x[:, i], y_avarg)) / n
        res.append(b)
    return res

def s_kv(y, y_aver, n, m):
    res = []
    for i in range(n):
        s = sum([(y_aver[i] - y[i][j]) ** 2 for j in range(m)]) / m
        res.append(round(s, 3))
    return res

#------------
def kriteriy_studenta(x, y, y_aver, n, m):
    start_time = time.monotonic()
    S_kv = s_kv(y, y_aver, n, m)
    s_kv_aver = sum(S_kv) / n

    s_Bs = (s_kv_aver / n / m) ** 0.5
    Bs = bs(x, y_aver, n)
    ts = [round(abs(B) / s_Bs, 3) for B in Bs]
    end_time = time.monotonic()
    time_S = (end_time - start_time) * 1000
    print(f"Час виконання Стьюдента: {time_S:.3f} ms")
    return ts
#------------

#------------
def adequacy_Fishera(y, y_avarg, y_new, n, m, d):
    start_time = time.monotonic()
    S_ad = m / (n - d) * sum([(y_new[i] - y_avarg[i])**2 for i in range(len(y))])
    S_kv = count_dispersion(y, y_avarg, n, m)
    S_kv_aver = sum(S_kv) / n
    end_time = time.monotonic()
    time_F = (end_time - start_time) * 1000
    print(f"Час виконання Фiшера: {time_F:.3f} ms")
    return S_ad / S_kv_aver
#------------

#Перевiрка
def check(X, Y, B, n, m):
    f1 = m - 1
    f2 = n
    f3 = f1 * f2
    q = 0.05

    student = partial(t.ppf, q=1 - q)
    t_student = student(df=f3)

    G_kr = cohren(f1, f2)

    y_aver = [round(sum(i) / len(i), 3) for i in Y]

    d_p = s_kv(Y, y_aver, n, m)
    print(f'Дисперсія y: {d_p}')

    Gp = check_criter_Cochran(Y, y_aver, n, m)
    print(f'Gp = {Gp}')
    if Gp < G_kr:
        print(f'Дисперсії однорідні {1 - q}')
    else:
        print("Збільшити кількість дослідів")
        m += 1
        main(n, m)

    ts = kriteriy_studenta(X[:, 1:], Y, y_aver, n, m)
    print(f'Критерій Стьюдента: {ts}')
    res = [t for t in ts if t > t_student]
    k = [B[i] for i in range(len(ts)) if ts[i] in res]
    print('\nКоефіцієнти статистично незначущі {} '.format(
        [round(i, 3) for i in B if i not in k]))

    y_new = []
    for j in range(n):
        y_new.append(suma([X[j][i] for i in range(len(ts)) if ts[i] in res], k))

    print(f'\nЗначення "y" з коефіцієнтами {k}')
    print(y_new)

    d = len(res)
    if d >= n:
        print('\nF4 <= 0')
        print('')
        return
    f4 = n - d

    F_p = adequacy_Fishera(Y, y_aver, y_new, n, m, d)

    fisher = partial(f.ppf, q=0.95)
    f_t = fisher(dfn=f4, dfd=f3)
    print('\nПеревірка адекватності за критерієм Фішера')
    print('Fp =', F_p)
    print('F_t =', f_t)
    if F_p < f_t:
        print('Математична модель є адекватна')
    else:
        print('Математична модель не є адекватною')


def main(n, m):
    X5, Y5, X5_norm = matrixs(n, m)

    y5_aver = [round(sum(i) / len(i), 3) for i in Y5]
    B5 = find_coef(X5, y5_aver)

    check(X5_norm, Y5, B5, n, m)


if __name__ == '__main__':
    main(15, 3)
